{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes: \n",
    "    \n",
    "    three input vectors (or tensors if one-hot encoded) for the candidate names, the station callsigns and the committee names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"source/training.csv\"\n",
    "filings = \"source/ftf-all-filings.tsv\"\n",
    "docs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>page</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>token</th>\n",
       "      <th>gross_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.000</td>\n",
       "      <td>25.145</td>\n",
       "      <td>439.448</td>\n",
       "      <td>25.189</td>\n",
       "      <td>Print</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.672</td>\n",
       "      <td>25.145</td>\n",
       "      <td>458.568</td>\n",
       "      <td>25.189</td>\n",
       "      <td>Date</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474.001</td>\n",
       "      <td>25.145</td>\n",
       "      <td>505.137</td>\n",
       "      <td>25.189</td>\n",
       "      <td>10/09/12</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>533.251</td>\n",
       "      <td>25.145</td>\n",
       "      <td>551.931</td>\n",
       "      <td>25.189</td>\n",
       "      <td>Page</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>560.251</td>\n",
       "      <td>25.145</td>\n",
       "      <td>564.699</td>\n",
       "      <td>25.189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               slug  page       x0      y0  \\\n",
       "0  459790-nrsc_mandel_rep_senate_1010_101412_314271   0.0  423.000  25.145   \n",
       "1  459790-nrsc_mandel_rep_senate_1010_101412_314271   0.0  441.672  25.145   \n",
       "2  459790-nrsc_mandel_rep_senate_1010_101412_314271   0.0  474.001  25.145   \n",
       "3  459790-nrsc_mandel_rep_senate_1010_101412_314271   0.0  533.251  25.145   \n",
       "4  459790-nrsc_mandel_rep_senate_1010_101412_314271   0.0  560.251  25.145   \n",
       "\n",
       "        x1      y1     token  gross_amount  \n",
       "0  439.448  25.189     Print          0.00  \n",
       "1  458.568  25.189      Date          0.00  \n",
       "2  505.137  25.189  10/09/12          0.40  \n",
       "3  551.931  25.189      Page          0.00  \n",
       "4  564.699  25.189         1          0.25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv(train, nrows = docs)\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filing_type</th>\n",
       "      <th>contract_number</th>\n",
       "      <th>url</th>\n",
       "      <th>committee</th>\n",
       "      <th>agency</th>\n",
       "      <th>callsign</th>\n",
       "      <th>dc_slug</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>gross_amount</th>\n",
       "      <th>market_id</th>\n",
       "      <th>upload_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23969</td>\n",
       "      <td>Federal</td>\n",
       "      <td>314271</td>\n",
       "      <td>/collect/files/59438/Political File/2012/Feder...</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "      <td>STRATEGIC MEDIA SERVICES</td>\n",
       "      <td>WCPO-TV</td>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>21100.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012-10-10 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2333</td>\n",
       "      <td>Non-Candidate Issue Ads</td>\n",
       "      <td>9792042</td>\n",
       "      <td>/collect/files/11289/Political File/2012/Non-C...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>MENTZER MEDIA SERVICES</td>\n",
       "      <td>WKRC-TV</td>\n",
       "      <td>416491-collect-files-11289-political-file-2012...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2012-08-14 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31990</td>\n",
       "      <td>Federal</td>\n",
       "      <td>336298</td>\n",
       "      <td>/collect/files/73910/Political File/2012/Feder...</td>\n",
       "      <td>POL/R TERRY/D/PRES/US</td>\n",
       "      <td>KATHLEEN OFFERMAN</td>\n",
       "      <td>WPXI</td>\n",
       "      <td>470297-101612-terry-contract-2-13504017232906-...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2012-10-16 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33211</td>\n",
       "      <td>Federal</td>\n",
       "      <td>116252</td>\n",
       "      <td>/collect/files/73123/Political File/2012/Feder...</td>\n",
       "      <td>COMMITTEE TO ELECT SHANELLE JACKSON</td>\n",
       "      <td>SHANELLE JACKSON FOR CONGRESS</td>\n",
       "      <td>WJBK</td>\n",
       "      <td>473630-116252-0-13442821773323-_-pdf</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2012-08-06 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6213</td>\n",
       "      <td>Non-Candidate Issue Ads</td>\n",
       "      <td>48982</td>\n",
       "      <td>/collect/files/72313/Political File/2012/Non-C...</td>\n",
       "      <td>PRIORITIES USA ACTION</td>\n",
       "      <td>MUNDY KATOWITZ MEDIA</td>\n",
       "      <td>WHP-TV</td>\n",
       "      <td>420426-collect-files-72313-political-file-2012...</td>\n",
       "      <td>https://s3.amazonaws.com/s3.documentcloud.org/...</td>\n",
       "      <td>9335.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2012-08-13 00:00:00 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id              filing_type contract_number  \\\n",
       "0  23969                  Federal          314271   \n",
       "1   2333  Non-Candidate Issue Ads         9792042   \n",
       "2  31990                  Federal          336298   \n",
       "3  33211                  Federal          116252   \n",
       "4   6213  Non-Candidate Issue Ads           48982   \n",
       "\n",
       "                                                 url  \\\n",
       "0  /collect/files/59438/Political File/2012/Feder...   \n",
       "1  /collect/files/11289/Political File/2012/Non-C...   \n",
       "2  /collect/files/73910/Political File/2012/Feder...   \n",
       "3  /collect/files/73123/Political File/2012/Feder...   \n",
       "4  /collect/files/72313/Political File/2012/Non-C...   \n",
       "\n",
       "                             committee                         agency  \\\n",
       "0               NRSC-MANDEL/REPUBLICAN       STRATEGIC MEDIA SERVICES   \n",
       "1                      60+ ASSOCIATION         MENTZER MEDIA SERVICES   \n",
       "2                POL/R TERRY/D/PRES/US              KATHLEEN OFFERMAN   \n",
       "3  COMMITTEE TO ELECT SHANELLE JACKSON  SHANELLE JACKSON FOR CONGRESS   \n",
       "4                PRIORITIES USA ACTION           MUNDY KATOWITZ MEDIA   \n",
       "\n",
       "  callsign                                            dc_slug  \\\n",
       "0  WCPO-TV   459790-nrsc_mandel_rep_senate_1010_101412_314271   \n",
       "1  WKRC-TV  416491-collect-files-11289-political-file-2012...   \n",
       "2     WPXI  470297-101612-terry-contract-2-13504017232906-...   \n",
       "3     WJBK               473630-116252-0-13442821773323-_-pdf   \n",
       "4   WHP-TV  420426-collect-files-72313-political-file-2012...   \n",
       "\n",
       "                                       thumbnail_url  gross_amount  market_id  \\\n",
       "0  https://s3.amazonaws.com/s3.documentcloud.org/...       21100.0       35.0   \n",
       "1  https://s3.amazonaws.com/s3.documentcloud.org/...        6250.0       35.0   \n",
       "2  https://s3.amazonaws.com/s3.documentcloud.org/...          30.0       23.0   \n",
       "3  https://s3.amazonaws.com/s3.documentcloud.org/...        1170.0       11.0   \n",
       "4  https://s3.amazonaws.com/s3.documentcloud.org/...        9335.0       41.0   \n",
       "\n",
       "               upload_date  \n",
       "0  2012-10-10 00:00:00 UTC  \n",
       "1  2012-08-14 00:00:00 UTC  \n",
       "2  2012-10-16 00:00:00 UTC  \n",
       "3  2012-08-06 00:00:00 UTC  \n",
       "4  2012-08-13 00:00:00 UTC  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.read_csv(filings,nrows = docs, sep='\\t')\n",
    "dff.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Bash Code: \n",
    "    \n",
    "    \n",
    "    head -n 50 training.csv\n",
    "    head -n 30 ftf-all-filings.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>token</th>\n",
       "      <th>committee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>Print</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>Date</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>10/09/12</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>Page</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>1</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>of</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>3</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>WCPO</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>Flight</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               slug     token  \\\n",
       "0  459790-nrsc_mandel_rep_senate_1010_101412_314271     Print   \n",
       "1  459790-nrsc_mandel_rep_senate_1010_101412_314271      Date   \n",
       "2  459790-nrsc_mandel_rep_senate_1010_101412_314271  10/09/12   \n",
       "3  459790-nrsc_mandel_rep_senate_1010_101412_314271      Page   \n",
       "4  459790-nrsc_mandel_rep_senate_1010_101412_314271         1   \n",
       "5  459790-nrsc_mandel_rep_senate_1010_101412_314271        of   \n",
       "6  459790-nrsc_mandel_rep_senate_1010_101412_314271         3   \n",
       "7  459790-nrsc_mandel_rep_senate_1010_101412_314271      WCPO   \n",
       "8  459790-nrsc_mandel_rep_senate_1010_101412_314271     ORDER   \n",
       "9  459790-nrsc_mandel_rep_senate_1010_101412_314271    Flight   \n",
       "\n",
       "                committee  \n",
       "0  NRSC-MANDEL/REPUBLICAN  \n",
       "1  NRSC-MANDEL/REPUBLICAN  \n",
       "2  NRSC-MANDEL/REPUBLICAN  \n",
       "3  NRSC-MANDEL/REPUBLICAN  \n",
       "4  NRSC-MANDEL/REPUBLICAN  \n",
       "5  NRSC-MANDEL/REPUBLICAN  \n",
       "6  NRSC-MANDEL/REPUBLICAN  \n",
       "7  NRSC-MANDEL/REPUBLICAN  \n",
       "8  NRSC-MANDEL/REPUBLICAN  \n",
       "9  NRSC-MANDEL/REPUBLICAN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.merge(left=dft, right=dff, how='left', left_on='slug', right_on='dc_slug')\n",
    "#df_all = df_all[['slug', 'page', 'x0', 'y0', 'x1', 'y1', 'token', 'gross_amount_x', 'committee']]\n",
    "df_all = df_all[['slug', 'token', 'committee']]\n",
    "\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'459790-nrsc_mandel_rep_senate_1010_101412_314271'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['slug'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>committee</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>416903-collect-files-39738-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 08/14/12 Page 1 of 1 WXIX ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>416904-collect-files-39738-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 08/14/12 Page 1 of 1 WXIX ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416945-collect-files-59441-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 08/17/12 Page 1 of 2 WEWS ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>416946-collect-files-59441-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 08/17/12 Page 1 of 2 WEWS ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>417116-collect-files-65593-political-file-2012...</td>\n",
       "      <td>RNC</td>\n",
       "      <td>Print Date 08/10/12 18:15:03 Page 1 of 6 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>419754-collect-files-65684-political-file-2012...</td>\n",
       "      <td>WARREN/D/SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/23/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>419756-collect-files-65684-political-file-2012...</td>\n",
       "      <td>WARREN/D/SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/23/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>419761-collect-files-65684-political-file-2012...</td>\n",
       "      <td>WARREN/D/SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/29/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>419765-collect-files-65684-political-file-2012...</td>\n",
       "      <td>WARREN/D/SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/09/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>420232-collect-files-39746-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/14/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>420233-collect-files-39746-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/14/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>420426-collect-files-72313-political-file-2012...</td>\n",
       "      <td>PRIORITIES USA ACTION</td>\n",
       "      <td>Print Date 08/13/12 16:34:44 Page 1 of 2 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>424758-collect-files-35576-political-file-2012...</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 09/06/12 11:24:44 Page 1 of 5 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>424793-collect-files-39738-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 09/06/12 Page 1 of 1 WXIX ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>424794-collect-files-39738-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 09/06/12 Page 1 of 1 WXIX ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>424869-collect-files-11909-political-file-2012...</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 09/06/12 11:26:36 Page 1 of 2 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>431304-collect-files-35576-political-file-2012...</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 09/11/12 13:08:25 Page 1 of 6 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>431736-collect-files-11909-political-file-2012...</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 09/11/12 12:19:56 Page 1 of 2 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>433811-collect-files-23079-political-file-2012...</td>\n",
       "      <td>MINNESOTA UNITED FOR ALL FAMILIES</td>\n",
       "      <td>Print Date 09/14/12 09:51:45 Page 1 of 3 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>433812-collect-files-23079-political-file-2012...</td>\n",
       "      <td>DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE</td>\n",
       "      <td>Print Date 09/14/12 13:45:37 Page 1 of 3 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>433983-collect-files-68883-political-file-2012...</td>\n",
       "      <td>DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE</td>\n",
       "      <td>Contract Agreement Between: Print Date 09/17/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>442594-collect-files-73195-political-file-2012...</td>\n",
       "      <td>60+ ASSOCIATION</td>\n",
       "      <td>Print Date 09/24/12 10:41:17 Page 1 of 1 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>457315-romney-for-president-wo-10-6-order</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 10/05/12 10:53:08 Page 1 of 3 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>457316-romney-for-president-wo-10-6-rev-order</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 10/05/12 11:04:05 Page 1 of 3 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>457688-romney-for-president-wo-9-12-rev-order</td>\n",
       "      <td>ROMNEY FOR PRESIDENT</td>\n",
       "      <td>Print Date 10/07/12 14:10:02 Page 1 of 5 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>459790-nrsc_mandel_rep_senate_1010_101412_314271</td>\n",
       "      <td>NRSC-MANDEL/REPUBLICAN</td>\n",
       "      <td>Print Date 10/09/12 Page 1 of 3 WCPO ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>469069-markell-10-16-22-13503282333116-_-pdf</td>\n",
       "      <td>MARKELL FOR DELAWARE</td>\n",
       "      <td>Acknowledgment of Agreement Between WPVI-TV PH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>469114-398590-1-13503368825844-_-pdf</td>\n",
       "      <td>DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE</td>\n",
       "      <td>Contract Agreement Between: Print Date 10/15/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>470233-arpaio-10_16722619-13504209200222-_-pdf</td>\n",
       "      <td>JOE ARPAIO FOR MARICOPA COUNTY SHERIFF</td>\n",
       "      <td>Print Date 10/15/12 15:13:30 Page 1 of 3 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>470385-65716-1-13503969050907-_-pdf</td>\n",
       "      <td>JOE PITTS 4 CONGRESS</td>\n",
       "      <td>Print Date 10/15/12 14:00:21 Page 1 of 2 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>470423-obrien-oct-15-17-buy-13503963034902-_-pdf</td>\n",
       "      <td>MIKE O'BRIEN FOR CONGRESS</td>\n",
       "      <td>Rep Order# 6863484 Ver# 1 Mod# 0 Status Confir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>470486-kirkpatrick_1009-1015rev6-1350349204965...</td>\n",
       "      <td>ANN KIRKPATRICK</td>\n",
       "      <td>Print Date 10/15/12 Page 1 of 6 KNXV ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>470493-nrcc-ie_1019-1025-est-3390-135034890611...</td>\n",
       "      <td>NRCC IE</td>\n",
       "      <td>Print Date 10/15/12 Page 1 of 2 KNXV ORDER Fli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>470655-dccc180368-13503423133267-_-pdf</td>\n",
       "      <td>DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE</td>\n",
       "      <td>Print Date 10/15/12 16:55:16 Page 1 of 5 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>473630-116252-0-13442821773323-_-pdf</td>\n",
       "      <td>COMMITTEE TO ELECT SHANELLE JACKSON</td>\n",
       "      <td>Contract Agreement Between: Print Date 08/06/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>480018-67579-1-13509285046144-_-pdf</td>\n",
       "      <td>CASEY/D/SENATE</td>\n",
       "      <td>Print Date 10/22/12 13:51:00 Page 1 of 2 ORDER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>510798-343280-1-13524180884487-_-pdf</td>\n",
       "      <td>MAJORITY PAC</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>511281-336563-4-13524183201766-_-pdf</td>\n",
       "      <td>RORABACK FOR CONGRESS</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>511282-339995-1-13524183255885-_-pdf</td>\n",
       "      <td>FRIENDS OF ELIZABETH ESTY</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>511283-342425-5-13524183101415-_-pdf</td>\n",
       "      <td>MURPHY FOR SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>511285-344110-0-13524181205225-_-pdf</td>\n",
       "      <td>MURPHY FOR SENATE</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>511286-334325-8-13524183157789-_-pdf</td>\n",
       "      <td>LINDA MCMAHON FOR SENATE 2012</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>511287-342495-1-13524183135098-_-pdf</td>\n",
       "      <td>LINDA MCMAHON FOR SENATE 2012</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>511288-342852-2-13524183124047-_-pdf</td>\n",
       "      <td>LINDA MCMAHON FOR SENATE 2012</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>511290-344206-2-13524181028832-_-pdf</td>\n",
       "      <td>CONNECTICUT'S FUTURE PAC</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>511291-345363-0-13524181183619-_-pdf</td>\n",
       "      <td>DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>511293-341356-4-13524181194607-_-pdf</td>\n",
       "      <td>GOVERNMENT INTEGRITY FUND</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>511295-344107-1-13524180973818-_-pdf</td>\n",
       "      <td>HOUSE MAJORITY PAC</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>511296-345028-0-13524180963339-_-pdf</td>\n",
       "      <td>HOUSE MAJORITY PAC</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>511297-345394-0-13524180941700-_-pdf</td>\n",
       "      <td>HOUSE MAJORITY PAC</td>\n",
       "      <td>Contract Agreement Between: Print Date 11/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 slug  \\\n",
       "0   416903-collect-files-39738-political-file-2012...   \n",
       "1   416904-collect-files-39738-political-file-2012...   \n",
       "2   416945-collect-files-59441-political-file-2012...   \n",
       "3   416946-collect-files-59441-political-file-2012...   \n",
       "4   417116-collect-files-65593-political-file-2012...   \n",
       "5   419754-collect-files-65684-political-file-2012...   \n",
       "6   419756-collect-files-65684-political-file-2012...   \n",
       "7   419761-collect-files-65684-political-file-2012...   \n",
       "8   419765-collect-files-65684-political-file-2012...   \n",
       "9   420232-collect-files-39746-political-file-2012...   \n",
       "10  420233-collect-files-39746-political-file-2012...   \n",
       "11  420426-collect-files-72313-political-file-2012...   \n",
       "12  424758-collect-files-35576-political-file-2012...   \n",
       "13  424793-collect-files-39738-political-file-2012...   \n",
       "14  424794-collect-files-39738-political-file-2012...   \n",
       "15  424869-collect-files-11909-political-file-2012...   \n",
       "16  431304-collect-files-35576-political-file-2012...   \n",
       "17  431736-collect-files-11909-political-file-2012...   \n",
       "18  433811-collect-files-23079-political-file-2012...   \n",
       "19  433812-collect-files-23079-political-file-2012...   \n",
       "20  433983-collect-files-68883-political-file-2012...   \n",
       "21  442594-collect-files-73195-political-file-2012...   \n",
       "22          457315-romney-for-president-wo-10-6-order   \n",
       "23      457316-romney-for-president-wo-10-6-rev-order   \n",
       "24      457688-romney-for-president-wo-9-12-rev-order   \n",
       "25   459790-nrsc_mandel_rep_senate_1010_101412_314271   \n",
       "26       469069-markell-10-16-22-13503282333116-_-pdf   \n",
       "27               469114-398590-1-13503368825844-_-pdf   \n",
       "28     470233-arpaio-10_16722619-13504209200222-_-pdf   \n",
       "29                470385-65716-1-13503969050907-_-pdf   \n",
       "30   470423-obrien-oct-15-17-buy-13503963034902-_-pdf   \n",
       "31  470486-kirkpatrick_1009-1015rev6-1350349204965...   \n",
       "32  470493-nrcc-ie_1019-1025-est-3390-135034890611...   \n",
       "33             470655-dccc180368-13503423133267-_-pdf   \n",
       "34               473630-116252-0-13442821773323-_-pdf   \n",
       "35                480018-67579-1-13509285046144-_-pdf   \n",
       "36               510798-343280-1-13524180884487-_-pdf   \n",
       "37               511281-336563-4-13524183201766-_-pdf   \n",
       "38               511282-339995-1-13524183255885-_-pdf   \n",
       "39               511283-342425-5-13524183101415-_-pdf   \n",
       "40               511285-344110-0-13524181205225-_-pdf   \n",
       "41               511286-334325-8-13524183157789-_-pdf   \n",
       "42               511287-342495-1-13524183135098-_-pdf   \n",
       "43               511288-342852-2-13524183124047-_-pdf   \n",
       "44               511290-344206-2-13524181028832-_-pdf   \n",
       "45               511291-345363-0-13524181183619-_-pdf   \n",
       "46               511293-341356-4-13524181194607-_-pdf   \n",
       "47               511295-344107-1-13524180973818-_-pdf   \n",
       "48               511296-345028-0-13524180963339-_-pdf   \n",
       "49               511297-345394-0-13524180941700-_-pdf   \n",
       "\n",
       "                                      committee  \\\n",
       "0                               60+ ASSOCIATION   \n",
       "1                               60+ ASSOCIATION   \n",
       "2                               60+ ASSOCIATION   \n",
       "3                               60+ ASSOCIATION   \n",
       "4                                           RNC   \n",
       "5                               WARREN/D/SENATE   \n",
       "6                               WARREN/D/SENATE   \n",
       "7                               WARREN/D/SENATE   \n",
       "8                               WARREN/D/SENATE   \n",
       "9                               60+ ASSOCIATION   \n",
       "10                              60+ ASSOCIATION   \n",
       "11                        PRIORITIES USA ACTION   \n",
       "12                         ROMNEY FOR PRESIDENT   \n",
       "13                              60+ ASSOCIATION   \n",
       "14                              60+ ASSOCIATION   \n",
       "15                         ROMNEY FOR PRESIDENT   \n",
       "16                         ROMNEY FOR PRESIDENT   \n",
       "17                         ROMNEY FOR PRESIDENT   \n",
       "18            MINNESOTA UNITED FOR ALL FAMILIES   \n",
       "19  DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE   \n",
       "20  DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE   \n",
       "21                              60+ ASSOCIATION   \n",
       "22                         ROMNEY FOR PRESIDENT   \n",
       "23                         ROMNEY FOR PRESIDENT   \n",
       "24                         ROMNEY FOR PRESIDENT   \n",
       "25                       NRSC-MANDEL/REPUBLICAN   \n",
       "26                         MARKELL FOR DELAWARE   \n",
       "27     DEMOCRATIC SENATORIAL CAMPAIGN COMMITTEE   \n",
       "28       JOE ARPAIO FOR MARICOPA COUNTY SHERIFF   \n",
       "29                         JOE PITTS 4 CONGRESS   \n",
       "30                    MIKE O'BRIEN FOR CONGRESS   \n",
       "31                              ANN KIRKPATRICK   \n",
       "32                                      NRCC IE   \n",
       "33  DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE   \n",
       "34          COMMITTEE TO ELECT SHANELLE JACKSON   \n",
       "35                               CASEY/D/SENATE   \n",
       "36                                 MAJORITY PAC   \n",
       "37                        RORABACK FOR CONGRESS   \n",
       "38                    FRIENDS OF ELIZABETH ESTY   \n",
       "39                            MURPHY FOR SENATE   \n",
       "40                            MURPHY FOR SENATE   \n",
       "41                LINDA MCMAHON FOR SENATE 2012   \n",
       "42                LINDA MCMAHON FOR SENATE 2012   \n",
       "43                LINDA MCMAHON FOR SENATE 2012   \n",
       "44                     CONNECTICUT'S FUTURE PAC   \n",
       "45  DEMOCRATIC CONGRESSIONAL CAMPAIGN COMMITTEE   \n",
       "46                    GOVERNMENT INTEGRITY FUND   \n",
       "47                           HOUSE MAJORITY PAC   \n",
       "48                           HOUSE MAJORITY PAC   \n",
       "49                           HOUSE MAJORITY PAC   \n",
       "\n",
       "                                                token  \n",
       "0   Print Date 08/14/12 Page 1 of 1 WXIX ORDER Fli...  \n",
       "1   Print Date 08/14/12 Page 1 of 1 WXIX ORDER Fli...  \n",
       "2   Print Date 08/17/12 Page 1 of 2 WEWS ORDER Fli...  \n",
       "3   Print Date 08/17/12 Page 1 of 2 WEWS ORDER Fli...  \n",
       "4   Print Date 08/10/12 18:15:03 Page 1 of 6 ORDER...  \n",
       "5   Contract Agreement Between: Print Date 08/23/1...  \n",
       "6   Contract Agreement Between: Print Date 08/23/1...  \n",
       "7   Contract Agreement Between: Print Date 08/29/1...  \n",
       "8   Contract Agreement Between: Print Date 08/09/1...  \n",
       "9   Contract Agreement Between: Print Date 08/14/1...  \n",
       "10  Contract Agreement Between: Print Date 08/14/1...  \n",
       "11  Print Date 08/13/12 16:34:44 Page 1 of 2 ORDER...  \n",
       "12  Print Date 09/06/12 11:24:44 Page 1 of 5 ORDER...  \n",
       "13  Print Date 09/06/12 Page 1 of 1 WXIX ORDER Fli...  \n",
       "14  Print Date 09/06/12 Page 1 of 1 WXIX ORDER Fli...  \n",
       "15  Print Date 09/06/12 11:26:36 Page 1 of 2 ORDER...  \n",
       "16  Print Date 09/11/12 13:08:25 Page 1 of 6 ORDER...  \n",
       "17  Print Date 09/11/12 12:19:56 Page 1 of 2 ORDER...  \n",
       "18  Print Date 09/14/12 09:51:45 Page 1 of 3 ORDER...  \n",
       "19  Print Date 09/14/12 13:45:37 Page 1 of 3 ORDER...  \n",
       "20  Contract Agreement Between: Print Date 09/17/1...  \n",
       "21  Print Date 09/24/12 10:41:17 Page 1 of 1 ORDER...  \n",
       "22  Print Date 10/05/12 10:53:08 Page 1 of 3 ORDER...  \n",
       "23  Print Date 10/05/12 11:04:05 Page 1 of 3 ORDER...  \n",
       "24  Print Date 10/07/12 14:10:02 Page 1 of 5 ORDER...  \n",
       "25  Print Date 10/09/12 Page 1 of 3 WCPO ORDER Fli...  \n",
       "26  Acknowledgment of Agreement Between WPVI-TV PH...  \n",
       "27  Contract Agreement Between: Print Date 10/15/1...  \n",
       "28  Print Date 10/15/12 15:13:30 Page 1 of 3 ORDER...  \n",
       "29  Print Date 10/15/12 14:00:21 Page 1 of 2 ORDER...  \n",
       "30  Rep Order# 6863484 Ver# 1 Mod# 0 Status Confir...  \n",
       "31  Print Date 10/15/12 Page 1 of 6 KNXV ORDER Fli...  \n",
       "32  Print Date 10/15/12 Page 1 of 2 KNXV ORDER Fli...  \n",
       "33  Print Date 10/15/12 16:55:16 Page 1 of 5 ORDER...  \n",
       "34  Contract Agreement Between: Print Date 08/06/1...  \n",
       "35  Print Date 10/22/12 13:51:00 Page 1 of 2 ORDER...  \n",
       "36  Contract Agreement Between: Print Date 11/08/1...  \n",
       "37  Contract Agreement Between: Print Date 11/08/1...  \n",
       "38  Contract Agreement Between: Print Date 11/08/1...  \n",
       "39  Contract Agreement Between: Print Date 11/08/1...  \n",
       "40  Contract Agreement Between: Print Date 11/08/1...  \n",
       "41  Contract Agreement Between: Print Date 11/08/1...  \n",
       "42  Contract Agreement Between: Print Date 11/08/1...  \n",
       "43  Contract Agreement Between: Print Date 11/08/1...  \n",
       "44  Contract Agreement Between: Print Date 11/08/1...  \n",
       "45  Contract Agreement Between: Print Date 11/08/1...  \n",
       "46  Contract Agreement Between: Print Date 11/08/1...  \n",
       "47  Contract Agreement Between: Print Date 11/08/1...  \n",
       "48  Contract Agreement Between: Print Date 11/08/1...  \n",
       "49  Contract Agreement Between: Print Date 11/08/1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group = df_all.groupby(['slug','committee'])['token'].apply(lambda a: ' '.join([str(x) for x in a])).reset_index()\n",
    "df_group.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416903-collect-files-39738-political-file-2012-non\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Print Date 08/14/12 Page 1 of 1 WXIX ORDER Flight Dates08/15/12-08/21/12 Order Sep 00:00:00 Product Estimate # 1224 Contract / Revision 808557 / 60 PLUS ASSOC SENATE Alt Order # 06276486 Original Date / Revision Agency Com 15% Billing Type Cash 08/14/12 08/14/12 Order Type Political Billing Contact Billing Cycle EOM/EOC Advertiser60 Plus Assoc 600 Farimont Avenue Billing CalendarBROADCAST Suite 306 Demographic A35+ Towson, MD 21286 Agency Mentzer Media Services Rev Codes Agency Political Pol-Issue Buying Contact Sales Office T-DC Product Codes PL20 Sales Region National Priority P 1 600 Farimont Avenue Suite 306 Agency Ref Advertiser Ref Towson, MD 21286 Primary Account Executive Aaron Ashe Account Executive Order% Start Date End Date Aaron Ashe 100% Order Share % Market Value Competing Station % of Order Amount EXIX % WBQC % WCET % WCPO % WCVN % WKON % WKRC % WLWT % WPTO % WSTR % Order Totals Billing Plan Month # of Spots Net Amount Gross Amount Rating Start Date End Date # Spots Net AmountGross Amount August 2012 2 $765.00 $900.00 0.00 07/30/12 08/19/12 2 $765.00 $900.00 Totals 2 $765.00 $900.00 0.00 Totals Ln Ch Start End Inventory Code Break Start/End Time Days Len Spots Rate Pri RtgType Spots Amount E 1 WXIX 08/17/12 08/17/12 News @ 7a Comm 7a-9a ----1-- :30 1 $600.00P 1 0.00 NM 1 $600.00 News @ 7am (7:30 AM-8:00 AM) Start Date End Date Weekdays Spots/Week Rate Rating Week: 08/13/12 08/19/12 ----1-- 1 $600.00 0.00 E 2 WXIX 08/19/12 08/19/12 FOX News Sunday Comm 8am-11am ------1 :30 1 $300.00P 1 0.00 NM 1 $300.00 Fox News Sunday (10:00 AM-11:00 AM) Start Date End Date Weekdays Spots/Week Rate Rating Week: 08/13/12 08/19/12 ------1 1 $300.00 0.00 Totals 2 $900.00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_group['slug'][0])\n",
    "\n",
    "' '.join(df_all[df_all['slug'] == '416903-collect-files-39738-political-file-2012-non']['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/migrate to convert TF1 code to TF2\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying this method to our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 1000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "input_texts = df_group['token'][:num_samples]\n",
    "\n",
    "input_characters = set()\n",
    "for token in input_texts:\n",
    "        for char in token:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "            if ' ' not in input_characters: \n",
    "                input_characters.add(' ')\n",
    "        if '\\t' not in input_characters: \n",
    "            input_characters.add('\\t')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_texts = []\n",
    "target_texts = df_group['committee'][:num_samples]\n",
    "\n",
    "target_characters = set()\n",
    "for token in target_texts:\n",
    "    if token != 'nan':\n",
    "        for char in token:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "        if ' ' not in target_characters: \n",
    "            target_characters.add(' ')\n",
    "        if '\\t' not in target_characters: \n",
    "            target_characters.add('\\t')        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 87\n",
      "Number of unique output tokens: 35\n",
      "Max sequence length for inputs: 78045\n",
      "Max sequence length for outputs: 86\n"
     ]
    }
   ],
   "source": [
    "input_characters = list(input_characters)\n",
    "target_characters = list(target_characters)\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "#print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "#print(input_texts[:10])\n",
    "#print(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4': 0, 'F': 1, 'c': 2, 'd': 3, 'A': 4, ')': 5, '9': 6, 'g': 7, 'M': 8, ']': 9, 'U': 10, '?': 11, 'B': 12, 'O': 13, 'e': 14, 'r': 15, 'i': 16, 'X': 17, '.': 18, '=': 19, 'R': 20, '3': 21, 'H': 22, 'u': 23, 'Q': 24, '<': 25, '&': 26, 'V': 27, 'W': 28, '%': 29, '\"': 30, 'h': 31, 'N': 32, '2': 33, 'v': 34, ',': 35, \"'\": 36, 'L': 37, 'y': 38, '/': 39, '[': 40, '’': 41, '8': 42, '0': 43, 's': 44, 't': 45, 'f': 46, '6': 47, 'p': 48, 'm': 49, 'P': 50, ':': 51, '+': 52, 'Z': 53, '\\t': 54, 'J': 55, '5': 56, '(': 57, '#': 58, 'G': 59, 'x': 60, ';': 61, 'k': 62, 'b': 63, 'T': 64, '-': 65, 'I': 66, 'o': 67, '@': 68, 'a': 69, 'C': 70, 'K': 71, 'z': 72, 'j': 73, 'q': 74, 'n': 75, '*': 76, 'w': 77, 'l': 78, 'E': 79, '1': 80, '$': 81, ' ': 82, 'S': 83, 'Y': 84, 'D': 85, '7': 86}\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "print (input_token_index)\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    \n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        #decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense/Identity:0\", shape=(None, None, 35), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44 samples, validate on 11 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('s2s_politics1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# #Sequence to sequence example in Keras (character-level).\n",
    "# This script demonstrates how to implement a basic character-level\n",
    "# sequence-to-sequence model. We apply it to translating\n",
    "# short English sentences into short French sentences,\n",
    "# character-by-character. Note that it is fairly unusual to\n",
    "# do character-level machine translation, as word-level\n",
    "# models are more common in this domain.\n",
    "# **Summary of the algorithm**\n",
    "# - We start with input sequences from a domain (e.g. English sentences)\n",
    "#     and corresponding target sequences from another domain\n",
    "#     (e.g. French sentences).\n",
    "# - An encoder LSTM turns input sequences to 2 state vectors\n",
    "#     (we keep the last LSTM state and discard the outputs).\n",
    "# - A decoder LSTM is trained to turn the target sequences into\n",
    "#     the same sequence but offset by one timestep in the future,\n",
    "#     a training process called \"teacher forcing\" in this context.\n",
    "#     It uses as initial state the state vectors from the encoder.\n",
    "#     Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "#     given `targets[...t]`, conditioned on the input sequence.\n",
    "# - In inference mode, when we want to decode unknown input sequences, we:\n",
    "#     - Encode the input sequence into state vectors\n",
    "#     - Start with a target sequence of size 1\n",
    "#         (just the start-of-sequence character)\n",
    "#     - Feed the state vectors and 1-char target sequence\n",
    "#         to the decoder to produce predictions for the next character\n",
    "#     - Sample the next character using these predictions\n",
    "#         (we simply use argmax). \n",
    "#     - Append the sampled character to the target sequence\n",
    "#     - Repeat until we generate the end-of-sequence character or we\n",
    "#         hit the character limit.\n",
    "# **Data download**\n",
    "# [English to French sentence pairs.\n",
    "# ](http://www.manythings.org/anki/fra-eng.zip)\n",
    "# [Lots of neat sentence pairs datasets.\n",
    "# ](http://www.manythings.org/anki/)\n",
    "# **References**\n",
    "# - [Sequence to Sequence Learning with Neural Networks\n",
    "#    ](https://arxiv.org/abs/1409.3215)\n",
    "# - [Learning Phrase Representations using\n",
    "#     RNN Encoder-Decoder for Statistical Machine Translation\n",
    "#     ](https://arxiv.org/abs/1406.1078)\n",
    "# '''\n",
    "\n",
    "# batch_size = 64  # Batch size for training.\n",
    "# epochs = 100  # Number of epochs to train for.\n",
    "# latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "# num_samples = 10000  # Number of samples to train on.\n",
    "# # Path to the data txt file on disk.\n",
    "# data_path = 'fra-eng/fra.txt'\n",
    "\n",
    "# # Vectorize the data.\n",
    "# input_texts = []\n",
    "# target_texts = []\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "# with open(data_path, 'r', encoding='utf-8') as f:\n",
    "#     lines = f.read().split('\\n')\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "#     input_text, target_text, _ = line.split('\\t')\n",
    "#     # We use \"tab\" as the \"start sequence\" character\n",
    "#     # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     target_text = '\\t' + target_text + '\\n'\n",
    "#     input_texts.append(input_text)\n",
    "#     target_texts.append(target_text)\n",
    "#     for char in input_text:\n",
    "#         if char not in input_characters:\n",
    "#             input_characters.add(char)\n",
    "#     for char in target_text:\n",
    "#         if char not in target_characters:\n",
    "#             target_characters.add(char)\n",
    "\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "# print('Number of samples:', len(input_texts))\n",
    "# print('Number of unique input tokens:', num_encoder_tokens)\n",
    "# print('Number of unique output tokens:', num_decoder_tokens)\n",
    "# print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "# print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# input_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(input_characters)])\n",
    "# print(input_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "\n",
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "#     encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "#             decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "#     decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "#     decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "# # Define an input sequence and process it.\n",
    "# encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Set up the decoder, using `encoder_states` as initial state.\n",
    "# decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# # We set up our decoder to return full output sequences,\n",
    "# # and to return internal states as well. We don't use the\n",
    "# # return states in the training model, but we will use them in inference.\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# # Run training\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=0.2)\n",
    "# # Save model\n",
    "# model.save('s2s.h5')\n",
    "\n",
    "# # Next: inference mode (sampling).\n",
    "# # Here's the drill:\n",
    "# # 1) encode input and retrieve initial decoder state\n",
    "# # 2) run one step of decoder with this initial state\n",
    "# # and a \"start of sequence\" token as target.\n",
    "# # Output will be the next target token\n",
    "# # 3) Repeat with the current target token and current states\n",
    "\n",
    "# # Define sampling models\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "#     decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model(\n",
    "#     [decoder_inputs] + decoder_states_inputs,\n",
    "#     [decoder_outputs] + decoder_states)\n",
    "\n",
    "# # Reverse-lookup token index to decode sequences back to\n",
    "# # something readable.\n",
    "# reverse_input_char_index = dict(\n",
    "#     (i, char) for char, i in input_token_index.items())\n",
    "# reverse_target_char_index = dict(\n",
    "#     (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "# def decode_sequence(input_seq):\n",
    "#     # Encode the input as state vectors.\n",
    "#     states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "#     # Generate empty target sequence of length 1.\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "#     # Sampling loop for a batch of sequences\n",
    "#     # (to simplify, here we assume a batch of size 1).\n",
    "#     stop_condition = False\n",
    "#     decoded_sentence = ''\n",
    "#     while not stop_condition:\n",
    "#         output_tokens, h, c = decoder_model.predict(\n",
    "#             [target_seq] + states_value)\n",
    "\n",
    "#         # Sample a token\n",
    "#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "#         decoded_sentence += sampled_char\n",
    "\n",
    "#         # Exit condition: either hit max length\n",
    "#         # or find stop character.\n",
    "#         if (sampled_char == '\\n' or\n",
    "#            len(decoded_sentence) > max_decoder_seq_length):\n",
    "#             stop_condition = True\n",
    "\n",
    "#         # Update the target sequence (of length 1).\n",
    "#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#         target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "#         # Update states\n",
    "#         states_value = [h, c]\n",
    "\n",
    "#     return decoded_sentence\n",
    "\n",
    "\n",
    "# for seq_index in range(100):\n",
    "#     # Take one sequence (part of the training set)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print('-')\n",
    "#     print('Input sentence:', input_texts[seq_index])\n",
    "#     print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64  # Batch size for training.\n",
    "# epochs = 100  # Number of epochs to train for.\n",
    "# latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "# num_samples = 10000  # Number of samples to train on.\n",
    "# # Path to the data txt file on disk.\n",
    "# data_path = 'fra-eng/fra.txt'\n",
    "\n",
    "# # Vectorize the data.\n",
    "# input_texts = []\n",
    "# target_texts = []\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "# with open(data_path, 'r', encoding='utf-8') as f:\n",
    "#     lines = f.read().split('\\n')\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "#     input_text, target_text, _ = line.split('\\t')\n",
    "#     # We use \"tab\" as the \"start sequence\" character\n",
    "#     # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     target_text = '\\t' + target_text + '\\n'\n",
    "#     input_texts.append(input_text)\n",
    "#     target_texts.append(target_text)\n",
    "#     for char in input_text:\n",
    "#         if char not in input_characters:\n",
    "#             input_characters.add(char)\n",
    "#     for char in target_text:\n",
    "#         if char not in target_characters:\n",
    "#             target_characters.add(char)\n",
    "\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "# print('Number of samples:', len(input_texts))\n",
    "# print('Number of unique input tokens:', num_encoder_tokens)\n",
    "# print('Number of unique output tokens:', num_decoder_tokens)\n",
    "# print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "# print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# input_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(input_characters)])\n",
    "# target_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(input_characters[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# #Sequence to sequence example in Keras (character-level).\n",
    "# This script demonstrates how to implement a basic character-level\n",
    "# sequence-to-sequence model. We apply it to translating\n",
    "# short English sentences into short French sentences,\n",
    "# character-by-character. Note that it is fairly unusual to\n",
    "# do character-level machine translation, as word-level\n",
    "# models are more common in this domain.\n",
    "# **Summary of the algorithm**\n",
    "# - We start with input sequences from a domain (e.g. English sentences)\n",
    "#     and corresponding target sequences from another domain\n",
    "#     (e.g. French sentences).\n",
    "# - An encoder LSTM turns input sequences to 2 state vectors\n",
    "#     (we keep the last LSTM state and discard the outputs).\n",
    "# - A decoder LSTM is trained to turn the target sequences into\n",
    "#     the same sequence but offset by one timestep in the future,\n",
    "#     a training process called \"teacher forcing\" in this context.\n",
    "#     It uses as initial state the state vectors from the encoder.\n",
    "#     Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "#     given `targets[...t]`, conditioned on the input sequence.\n",
    "# - In inference mode, when we want to decode unknown input sequences, we:\n",
    "#     - Encode the input sequence into state vectors\n",
    "#     - Start with a target sequence of size 1\n",
    "#         (just the start-of-sequence character)\n",
    "#     - Feed the state vectors and 1-char target sequence\n",
    "#         to the decoder to produce predictions for the next character\n",
    "#     - Sample the next character using these predictions\n",
    "#         (we simply use argmax).\n",
    "#     - Append the sampled character to the target sequence\n",
    "#     - Repeat until we generate the end-of-sequence character or we\n",
    "#         hit the character limit.\n",
    "# **Data download**\n",
    "# [English to French sentence pairs.\n",
    "# ](http://www.manythings.org/anki/fra-eng.zip)\n",
    "# [Lots of neat sentence pairs datasets.\n",
    "# ](http://www.manythings.org/anki/)\n",
    "# **References**\n",
    "# - [Sequence to Sequence Learning with Neural Networks\n",
    "#    ](https://arxiv.org/abs/1409.3215)\n",
    "# - [Learning Phrase Representations using\n",
    "#     RNN Encoder-Decoder for Statistical Machine Translation\n",
    "#     ](https://arxiv.org/abs/1406.1078)\n",
    "# '''\n",
    "\n",
    "# batch_size = 64  # Batch size for training.\n",
    "# epochs = 100  # Number of epochs to train for.\n",
    "# latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "# num_samples = 10000  # Number of samples to train on.\n",
    "# # Path to the data txt file on disk.\n",
    "# data_path = 'fra-eng/fra.txt'\n",
    "\n",
    "# # Vectorize the data.\n",
    "# input_texts = []\n",
    "# target_texts = []\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "# with open(data_path, 'r', encoding='utf-8') as f:\n",
    "#     lines = f.read().split('\\n')\n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "#     input_text, target_text, _ = line.split('\\t')\n",
    "#     # We use \"tab\" as the \"start sequence\" character\n",
    "#     # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     target_text = '\\t' + target_text + '\\n'\n",
    "#     input_texts.append(input_text)\n",
    "#     target_texts.append(target_text)\n",
    "#     for char in input_text:\n",
    "#         if char not in input_characters:\n",
    "#             input_characters.add(char)\n",
    "#     for char in target_text:\n",
    "#         if char not in target_characters:\n",
    "#             target_characters.add(char)\n",
    "\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "# print('Number of samples:', len(input_texts))\n",
    "# print('Number of unique input tokens:', num_encoder_tokens)\n",
    "# print('Number of unique output tokens:', num_decoder_tokens)\n",
    "# print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "# print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# input_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(input_characters)])\n",
    "# target_token_index = dict(\n",
    "#     [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "#     dtype='float32')\n",
    "\n",
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "#     encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "#             decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "#     decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "#     decoder_target_data[i, t:, target_token_index[' ']] = 1.\n",
    "# # Define an input sequence and process it.\n",
    "# encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# # We discard `encoder_outputs` and only keep the states.\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Set up the decoder, using `encoder_states` as initial state.\n",
    "# decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# # We set up our decoder to return full output sequences,\n",
    "# # and to return internal states as well. We don't use the\n",
    "# # return states in the training model, but we will use them in inference.\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "#                                      initial_state=encoder_states)\n",
    "# decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Define the model that will turn\n",
    "# # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# # Run training\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_split=0.2)\n",
    "# # Save model\n",
    "# model.save('s2s.h5')\n",
    "\n",
    "# # Next: inference mode (sampling).\n",
    "# # Here's the drill:\n",
    "# # 1) encode input and retrieve initial decoder state\n",
    "# # 2) run one step of decoder with this initial state\n",
    "# # and a \"start of sequence\" token as target.\n",
    "# # Output will be the next target token\n",
    "# # 3) Repeat with the current target token and current states\n",
    "\n",
    "# # Define sampling models\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "#     decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model(\n",
    "#     [decoder_inputs] + decoder_states_inputs,\n",
    "#     [decoder_outputs] + decoder_states)\n",
    "\n",
    "# # Reverse-lookup token index to decode sequences back to\n",
    "# # something readable.\n",
    "# reverse_input_char_index = dict(\n",
    "#     (i, char) for char, i in input_token_index.items())\n",
    "# reverse_target_char_index = dict(\n",
    "#     (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "# def decode_sequence(input_seq):\n",
    "#     # Encode the input as state vectors.\n",
    "#     states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "#     # Generate empty target sequence of length 1.\n",
    "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#     # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "#     # Sampling loop for a batch of sequences\n",
    "#     # (to simplify, here we assume a batch of size 1).\n",
    "#     stop_condition = False\n",
    "#     decoded_sentence = ''\n",
    "#     while not stop_condition:\n",
    "#         output_tokens, h, c = decoder_model.predict(\n",
    "#             [target_seq] + states_value)\n",
    "\n",
    "#         # Sample a token\n",
    "#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "#         sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "#         decoded_sentence += sampled_char\n",
    "\n",
    "#         # Exit condition: either hit max length\n",
    "#         # or find stop character.\n",
    "#         if (sampled_char == '\\n' or\n",
    "#            len(decoded_sentence) > max_decoder_seq_length):\n",
    "#             stop_condition = True\n",
    "\n",
    "#         # Update the target sequence (of length 1).\n",
    "#         target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "#         target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "#         # Update states\n",
    "#         states_value = [h, c]\n",
    "\n",
    "#     return decoded_sentence\n",
    "\n",
    "\n",
    "# for seq_index in range(100):\n",
    "#     # Take one sequence (part of the training set)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print('-')\n",
    "#     print('Input sentence:', input_texts[seq_index])\n",
    "#     print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
